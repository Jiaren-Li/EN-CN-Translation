{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571bfc36-03c6-4d25-a758-a18e72ea229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import codecs\n",
    "#import jieba\n",
    "from collections import Counter#计数器\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence ,pack_padded_sequence,pad_packed_sequence\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer#分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f14016-d574-46ea-9934-ed013460361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForMaskedLM, BertForNextSentencePrediction\n",
    " \n",
    "from transformers import BertModel\n",
    " \n",
    "model_name = 'bert-base-chinese'\n",
    "MODEL_PATH = '/bert-base-chinese/'\n",
    " \n",
    " # a.通过词典导入分词器\n",
    "tokenizer_zh = BertTokenizer.from_pretrained(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b53cf-e7b4-49a6-b299-62794ca8eeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f100e9-006d-4768-bdf8-14947e406849",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX = 0 #未知\n",
    "PAD_IDX = 1  #\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#DEBUG = True  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7228a41b-2d99-4308-9e8e-b59a21d92e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建词汇表\n",
    "def build_dict(sentences, max_words = 50000):\n",
    "    vocab = Counter(np.concatenate(sentences)).most_common(max_words)#最大单词数是50000\n",
    "    word_to_id = {w[0]: index + 2 for index, w in enumerate(vocab)}\n",
    "    word_to_id['UNK'] = UNK_IDX  #0\n",
    "    word_to_id['PAD'] = PAD_IDX  #1\n",
    "    id_to_word = {v: k for k, v in word_to_id.items()}\n",
    "    return word_to_id,id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1937227-c9ba-494f-a068-063405302d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用词典对原始句子编码 单词->数字\n",
    "\n",
    "def encode(en_sentences, ch_sentences, en_wtoi, zh_wtoi, sort_by_len=True):\n",
    "    \n",
    "    out_en_sentences = [[en_wtoi.get(w, UNK_IDX) for w in sent] for sent in en_sentences]\n",
    "    out_ch_sentences = [[zh_wtoi.get(w, UNK_IDX) for w in sent] for sent in ch_sentences]\n",
    "        \n",
    "    \n",
    "    #返回w对应的值，否则返回UNK_IDX\n",
    "    def len_argsort(seq):#按照长度进行排序\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "       \n",
    "    # 把中文和英文按照同样的顺序排序\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(out_en_sentences)\n",
    "        out_en_sentences = [out_en_sentences[i] for i in sorted_index]\n",
    "        out_ch_sentences = [out_ch_sentences[i] for i in sorted_index]\n",
    "        \n",
    "    return out_en_sentences, out_ch_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a42ea90c-9e0f-4ab0-a637-961e6763a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIR_PATH=\"/mnt/seq2seq_att/en-zh\"\n",
    "with codecs.open(DIR_PATH+'/train.zh','r','utf-8') as f1:\n",
    "    target_text=f1.read()\n",
    "with codecs.open(DIR_PATH+'/train.en','r','utf-8') as f2:\n",
    "    source_text=f2.read()\n",
    "with codecs.open(DIR_PATH+'/test.zh','r','utf-8') as f3:\n",
    "    test_target_text=f3.read()\n",
    "with codecs.open(DIR_PATH+'/test.en','r','utf-8') as f4:\n",
    "    test_source_text=f4.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49564fbf-a8c1-4bc8-80cf-463b3e8292c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2897366/2897366 [01:02<00:00, 46367.17it/s]\n",
      "100%|██████████| 4001/4001 [00:00<00:00, 55975.72it/s]\n",
      "100%|██████████| 3781317/3781317 [19:31<00:00, 3226.76it/s] \n",
      "100%|██████████| 4001/4001 [00:01<00:00, 2939.16it/s]\n"
     ]
    }
   ],
   "source": [
    "####设置句子最大长度为80\n",
    "max_length=80\n",
    "\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer#分词器\n",
    "tokenizer_en = get_tokenizer('basic_english')#按空格进行分割\n",
    "train_en = []\n",
    "for sentence in tqdm.tqdm(source_text.split(\"\\n\")):\n",
    "    text= tokenizer_en(sentence.lower())\n",
    "    if len(text)>max_length:\n",
    "        text=text[0:max_length]    \n",
    "    train_en.append([\"BOS\"] + text+ [\"EOS\"])#小写\n",
    "    \n",
    "\n",
    "test_en = []\n",
    "for sentence in tqdm.tqdm(test_source_text.split(\"\\n\")):\n",
    "    text= tokenizer_en(sentence.lower())\n",
    "    if len(text)>max_length:\n",
    "        text=text[0:max_length]    \n",
    "    test_en.append([\"BOS\"] + text + [\"EOS\"])#小写\n",
    "\n",
    "\n",
    "train_zh = []\n",
    "for sentence in tqdm.tqdm(target_text.split(\"\\n\")):\n",
    "    #train_zh.append([\"BOS\"] + tokenizer_cn(sentence) + [\"EOS\"])\n",
    "\n",
    "    text=tokenizer_zh.tokenize(sentence)\n",
    "    if len(text)>max_length:\n",
    "        text=text[0:max_length]\n",
    "    train_zh.append([\"BOS\"] + text + [\"EOS\"])\n",
    "\n",
    "test_zh = []\n",
    "for sentence in tqdm.tqdm(test_target_text.split(\"\\n\")):\n",
    "    text=tokenizer_zh.tokenize(sentence)\n",
    "    if len(text)>max_length:\n",
    "        text=text[0:max_length]\n",
    "    test_zh.append([\"BOS\"] +text+ [\"EOS\"])\n",
    "    \n",
    "train_zh =train_zh[0:2897366] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a0de32-b50a-4cfa-9249-bdee7e679048",
   "metadata": {},
   "outputs": [],
   "source": [
    "###生成词典\n",
    "en_wtoi, en_itow = build_dict(train_en)\n",
    "zh_wtoi, zh_itow = build_dict(train_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c624e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "###整数编码\n",
    "train_en_encode, train_zh_encode = encode(train_en, train_zh, en_wtoi, zh_wtoi)\n",
    "test_en_encode, test_zh_encode = encode(test_en, test_zh, en_wtoi, zh_wtoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b64aa63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_481/2090673378.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_en_encode_save=np.array(train_en_encode)\n",
      "/tmp/ipykernel_481/2090673378.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_zh_encode_save=np.array(train_zh_encode)\n",
      "/tmp/ipykernel_481/2090673378.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_zh_encode_save=np.array(test_zh_encode)\n",
      "/tmp/ipykernel_481/2090673378.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_en_encode_save=np.array(test_en_encode)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_en_encode_save=np.array(train_en_encode)\n",
    "np.save('train_en_bert.npy',train_en_encode_save)\n",
    "\n",
    "train_zh_encode_save=np.array(train_zh_encode)\n",
    "np.save('train_zh_bert.npy',train_zh_encode_save)\n",
    "\n",
    "test_zh_encode_save=np.array(test_zh_encode)\n",
    "np.save('test_zh_bert.npy',test_zh_encode_save)\n",
    "\n",
    "test_en_encode_save=np.array(test_en_encode)\n",
    "np.save('test_en_bert.npy',test_en_encode_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6a1d7e-5838-4f7b-97f9-5a5b65e46e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('en_wtoi_bert.npy',en_wtoi)\n",
    "\n",
    "np.save('en_itow_bert.npy',en_itow)\n",
    "\n",
    "np.save('zh_wtoi_bert.npy',zh_wtoi)\n",
    "\n",
    "np.save('zh_itow_bert.npy',zh_itow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28da4abe-6ac8-431c-9156-4f1b7e41807b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
