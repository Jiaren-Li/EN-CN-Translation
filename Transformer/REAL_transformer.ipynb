{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # transformer"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import jieba\n","import codecs\n","import collections\n","import sys\n","from operator import itemgetter\n","import tqdm\n","\n","import time\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# import os\n","# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["DIR_PATH=\"/home/xujingzhou/en-zh\"\n"]},{"cell_type":"markdown","metadata":{},"source":[" ### 分词、清洗、建立SubwordTextEncoder\n"," > 建立过程在subwordTextEncoder_*.py中完成了\n","\n"," 模型读取与展示"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[32346, 15384, 7, 12149, 2540, 32307]\n","How a hot day!\n","32346 ----> H\n","15384 ----> ow \n","7 ----> a \n","12149 ----> hot \n","2540 ----> day\n","32307 ----> !\n"]}],"source":["tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.load_from_file(DIR_PATH+'/en')\n","tokenizer_zh = tfds.deprecated.text.SubwordTextEncoder.load_from_file(DIR_PATH+'/zh')\n","sample_string = 'How a hot day!'\n","tokenized_string=tokenizer_en.encode(sample_string)\n","print(tokenized_string)\n","original_string=tokenizer_en.decode(tokenized_string)\n","print(original_string)\n","for ts in tokenized_string:\n","  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))\n","# print(\"-----------\")\n","# sample_string='你好,世界!'\n","# tokenized_string=tokenizer_zh.encode(sample_string)\n","# print(tokenized_string)\n","# original_string=tokenizer_zh.decode(tokenized_string)\n","# print(original_string)\n","# for ts in tokenized_string:\n","#   print ('{} ----> {}'.format(ts, tokenizer_zh.decode([ts])))\n","#YesYesYes!!\n"]},{"cell_type":"markdown","metadata":{},"source":[" 可以看到这个模型还是有一定的问题的，比如中文标点的表示方法等等，后续可能需要通过改进分词器来提高模型效果。"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["BUFFER_SIZE = 20000\n","BATCH_SIZE = 64\n"]},{"cell_type":"markdown","metadata":{},"source":[" 将开始和结束标记（token）添加到输入和目标。"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def encode(lang1, lang2):\n","  lang1 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n","      lang1.numpy()) + [tokenizer_en.vocab_size+1]\n","\n","  lang2 = [tokenizer_zh.vocab_size] + tokenizer_zh.encode(\n","      lang2.numpy()) + [tokenizer_zh.vocab_size+1]\n","  \n","  return lang1, lang2\n"]},{"cell_type":"markdown","metadata":{},"source":[" 这一步似乎并不需要"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["MAX_LENGTH = 80\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def filter_max_length(x, y, max_length=MAX_LENGTH):\n","  return tf.logical_and(tf.size(x) <= max_length,\n","                        tf.size(y) <= max_length)\n"]},{"cell_type":"markdown","metadata":{},"source":[" 创建encode函数"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def tf_encode(en, zh):\n","  result_en, result_zh = tf.py_function(encode, [en, zh], [tf.int64, tf.int64])\n","  result_en.set_shape([None])\n","  result_zh.set_shape([None])\n","\n","  return result_en, result_zh\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["#这里需要创建train——examples和test_examples：需要用到dataset\n","with codecs.open(DIR_PATH+'/train.zh','r','utf-8') as f:\n","    zh_data=f.readlines()\n","    #讲中文标点转为英文标点\n","    # zh_data=[i.replace('。', '.').replace('，', ',').replace('？', '?').replace('！', '!').replace('、',',') for i in zh_data]\n","    zh_data=tf.data.Dataset.from_tensor_slices(zh_data)\n","with codecs.open(DIR_PATH+'/train.en','r','utf-8') as f:\n","    # en_data=[]\n","    # #转小写\n","    # for line in f:\n","    #   en_data.append(line.lower())\n","    en_data=f.readlines()\n","    en_data=tf.data.Dataset.from_tensor_slices(en_data)\n","train_data=tf.data.Dataset.zip((en_data,zh_data))\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["loaded\n"]}],"source":["#val_Data\n","with codecs.open(DIR_PATH+'/test.zh','r','utf-8') as f:\n","    zh_data=f.readlines()\n","    # zh_data=[i.replace('。', '.').replace('，', ',').replace('？', '?').replace('！', '!').replace('、',',') for i in zh_data]\n","    zh_data=tf.data.Dataset.from_tensor_slices(zh_data)\n","with codecs.open(DIR_PATH+'/test.en','r','utf-8') as f:\n","    # en_data=[]\n","    # for line in f:\n","    #   en_data.append(line.lower())\n","    en_data=f.readlines()\n","    en_data=tf.data.Dataset.from_tensor_slices(en_data)\n","val_data=tf.data.Dataset.zip((en_data,zh_data))\n","print(\"loaded\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["train_dataset = train_data.map(tf_encode)#英中\n","train_dataset = train_dataset.filter(filter_max_length)\n","# 将数据集缓存到内存中以加快读取速度。\n","train_dataset = train_dataset.cache()\n","train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(BATCH_SIZE)\n","train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","val_dataset = val_data.map(tf_encode)\n","val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE)\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# pt_batch, en_batch = next(iter(train_dataset))\n","# pt_batch, en_batch\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def get_angles(pos, i, d_model):\n","  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n","  return pos * angle_rates\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def positional_encoding(position, d_model):\n","  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n","                          np.arange(d_model)[np.newaxis, :],\n","                          d_model)\n","  \n","  # 将 sin 应用于数组中的偶数索引（indices）；2i\n","  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","  \n","  # 将 cos 应用于数组中的奇数索引；2i+1\n","  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    \n","  pos_encoding = angle_rads[np.newaxis, ...]\n","    \n","  return tf.cast(pos_encoding, dtype=tf.float32)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 50, 512)\n"]}],"source":["pos_encoding = positional_encoding(50, 512)\n","print (pos_encoding.shape)\n","\n","# plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n","# plt.xlabel('Depth')\n","# plt.xlim((0, 512))\n","# plt.ylabel('Position')\n","# plt.colorbar()\n","# plt.show()\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def create_padding_mask(seq):\n","  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n","  \n","  # 添加额外的维度来将填充加到\n","  # 注意力对数（logits）。\n","  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n","# create_padding_mask(x)\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def create_look_ahead_mask(size):\n","  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n","  return mask  # (seq_len, seq_len)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# x = tf.random.uniform((1, 3))\n","# temp = create_look_ahead_mask(x.shape[1])\n","# temp\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def scaled_dot_product_attention(q, k, v, mask):\n","  \n","  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n","  \n","  # 缩放 matmul_qk\n","  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n","  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n","\n","  # 将 mask 加入到缩放的张量上。\n","  if mask is not None:\n","    scaled_attention_logits += (mask * -1e9)  \n","\n","  # softmax 在最后一个轴（seq_len_k）上归一化，因此分数\n","  # 相加等于1。\n","  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n","\n","  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n","\n","  return output, attention_weights\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["def print_out(q, k, v):\n","  temp_out, temp_attn = scaled_dot_product_attention(\n","      q, k, v, None)\n","  print ('Attention weights are:')\n","  print (temp_attn)\n","  print ('Output is:')\n","  print (temp_out)\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["np.set_printoptions(suppress=True)\n","\n","temp_k = tf.constant([[10,0,0],\n","                      [0,10,0],\n","                      [0,0,10],\n","                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n","\n","temp_v = tf.constant([[   1,0],\n","                      [  10,0],\n","                      [ 100,5],\n","                      [1000,6]], dtype=tf.float32)  # (4, 2)\n","\n","# 这条 `请求（query）符合第二个`主键（key）`，\n","# 因此返回了第二个`数值（value）`。\n","# temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n","# print_out(temp_q, temp_k, temp_v)\n","\n","# # %%\n","# # 这条请求符合重复出现的主键（第三第四个），\n","# # 因此，对所有的相关数值取了平均。\n","# temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n","# print_out(temp_q, temp_k, temp_v)\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# 这条请求符合第一和第二条主键，\n","# 因此，对它们的数值去了平均。\n","# temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n","# print_out(temp_q, temp_k, temp_v)\n","\n","# # %%\n","# temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n","# print_out(temp_q, temp_k, temp_v)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","    super(MultiHeadAttention, self).__init__()\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","    \n","    assert d_model % self.num_heads == 0\n","    \n","    self.depth = d_model // self.num_heads\n","    \n","    self.wq = tf.keras.layers.Dense(d_model)\n","    self.wk = tf.keras.layers.Dense(d_model)\n","    self.wv = tf.keras.layers.Dense(d_model)\n","    \n","    self.dense = tf.keras.layers.Dense(d_model)\n","        \n","  def split_heads(self, x, batch_size):\n","    \"\"\"分拆最后一个维度到 (num_heads, depth).\n","    转置结果使得形状为 (batch_size, num_heads, seq_len, depth)\n","    \"\"\"\n","    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(x, perm=[0, 2, 1, 3])\n","    \n","  def call(self, v, k, q, mask):\n","    batch_size = tf.shape(q)[0]\n","    \n","    q = self.wq(q)  # (batch_size, seq_len, d_model)\n","    k = self.wk(k)  # (batch_size, seq_len, d_model)\n","    v = self.wv(v)  # (batch_size, seq_len, d_model)\n","    \n","    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n","    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n","    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n","    \n","    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n","    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n","    scaled_attention, attention_weights = scaled_dot_product_attention(\n","        q, k, v, mask)\n","    \n","    # (batch_size, seq_len_q, num_heads, depth)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    concat_attention = tf.reshape(scaled_attention, \n","                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n","\n","    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n","        \n","    return output, attention_weights\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n","# y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n","# out, attn = temp_mha(y, k=y, q=y, mask=None)\n","# out.shape, attn.shape\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["def point_wise_feed_forward_network(d_model, dff):\n","  return tf.keras.Sequential([\n","      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n","      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n","  ])\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["# sample_ffn = point_wise_feed_forward_network(512, 2048)\n","# sample_ffn(tf.random.uniform((64, 50, 512))).shape\n"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["class EncoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(EncoderLayer, self).__init__()\n","\n","    self.mha = MultiHeadAttention(d_model, num_heads)\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n","\n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, training, mask):\n","\n","    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n","    attn_output = self.dropout1(attn_output, training=training)\n","    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n","    ffn_output = self.dropout2(ffn_output, training=training)\n","    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n","    \n","    return out2\n"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# sample_encoder_layer = EncoderLayer(512, 8, 2048)\n","\n","# sample_encoder_layer_output = sample_encoder_layer(\n","#     tf.random.uniform((64, 43, 512)), False, None)\n","\n","# sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads, dff, rate=0.1):\n","    super(DecoderLayer, self).__init__()\n","\n","    self.mha1 = MultiHeadAttention(d_model, num_heads)\n","    self.mha2 = MultiHeadAttention(d_model, num_heads)\n","\n","    self.ffn = point_wise_feed_forward_network(d_model, dff)\n"," \n","    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","    \n","    self.dropout1 = tf.keras.layers.Dropout(rate)\n","    self.dropout2 = tf.keras.layers.Dropout(rate)\n","    self.dropout3 = tf.keras.layers.Dropout(rate)\n","    \n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","    # enc_output.shape == (batch_size, input_seq_len, d_model)\n","\n","    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n","    attn1 = self.dropout1(attn1, training=training)\n","    out1 = self.layernorm1(attn1 + x)\n","    \n","    attn2, attn_weights_block2 = self.mha2(\n","        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n","    attn2 = self.dropout2(attn2, training=training)\n","    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n","    \n","    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n","    ffn_output = self.dropout3(ffn_output, training=training)\n","    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n","    \n","    return out3, attn_weights_block1, attn_weights_block2\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["# sample_decoder_layer = DecoderLayer(512, 8, 2048)\n","\n","# sample_decoder_layer_output, _, _ = sample_decoder_layer(\n","#     tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n","#     False, None, None)\n","\n","# sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Encoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, \n","                                            self.d_model)\n","    \n","    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","  \n","    self.dropout = tf.keras.layers.Dropout(rate)\n","        \n","  def call(self, x, training, mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    \n","    # 将嵌入和位置编码相加。\n","    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","\n","    x = self.dropout(x, training=training)\n","    \n","    for i in range(self.num_layers):\n","      x = self.enc_layers[i](x, training, mask)\n","    \n","    return x  # (batch_size, input_seq_len, d_model)\n"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["# sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n","#                          dff=2048, input_vocab_size=8500,\n","#                          maximum_position_encoding=10000)\n","\n","# sample_encoder_output = sample_encoder(tf.random.uniform((64, 62)), \n","#                                        training=False, mask=None)\n","\n","# print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n","               maximum_position_encoding, rate=0.1):\n","    super(Decoder, self).__init__()\n","\n","    self.d_model = d_model\n","    self.num_layers = num_layers\n","    \n","    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n","    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n","    \n","    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n","                       for _ in range(num_layers)]\n","    self.dropout = tf.keras.layers.Dropout(rate)\n","    \n","  def call(self, x, enc_output, training, \n","           look_ahead_mask, padding_mask):\n","\n","    seq_len = tf.shape(x)[1]\n","    attention_weights = {}\n","    \n","    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n","    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","    x += self.pos_encoding[:, :seq_len, :]\n","    \n","    x = self.dropout(x, training=training)\n","\n","    for i in range(self.num_layers):\n","      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n","                                             look_ahead_mask, padding_mask)\n","      \n","      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n","      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n","    \n","    # x.shape == (batch_size, target_seq_len, d_model)\n","    return x, attention_weights\n"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":["# sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n","#                          dff=2048, target_vocab_size=8000,\n","#                          maximum_position_encoding=5000)\n","\n","# output, attn = sample_decoder(tf.random.uniform((64, 26)), \n","#                               enc_output=sample_encoder_output, \n","#                               training=False, look_ahead_mask=None, \n","#                               padding_mask=None)\n","\n","# output.shape, attn['decoder_layer2_block2'].shape\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["class Transformer(tf.keras.Model):\n","  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n","               target_vocab_size, pe_input, pe_target, rate=0.1):\n","    super(Transformer, self).__init__()\n","\n","    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n","                           input_vocab_size, pe_input, rate)\n","\n","    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n","                           target_vocab_size, pe_target, rate)\n","\n","    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n","    \n","  def call(self, inp, tar, training, enc_padding_mask, \n","           look_ahead_mask, dec_padding_mask):\n","\n","    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n","    \n","    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n","    dec_output, attention_weights = self.decoder(\n","        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n","    \n","    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n","    \n","    return final_output, attention_weights\n"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["sample_transformer = Transformer(\n","    num_layers=2, d_model=512, num_heads=8, dff=2048, \n","    input_vocab_size=8500, target_vocab_size=8000, \n","    pe_input=10000, pe_target=6000)\n","\n","temp_input = tf.random.uniform((64, 62))\n","temp_target = tf.random.uniform((64, 26))\n","\n","# fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n","#                                enc_padding_mask=None, \n","#                                look_ahead_mask=None,\n","#                                dec_padding_mask=None)\n","\n","# fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)\n"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["num_layers = 4\n","d_model = 128\n","dff = 512\n","num_heads = 8\n","\n","input_vocab_size = tokenizer_en.vocab_size + 2\n","target_vocab_size = tokenizer_zh.vocab_size + 2\n","dropout_rate = 0.1\n"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","    \n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    \n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","    \n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["learning_rate = CustomSchedule(d_model)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n","                                     epsilon=1e-9)\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["# temp_learning_rate_schedule = CustomSchedule(d_model)\n","\n","# plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n","# plt.ylabel(\"Learning Rate\")\n","# plt.xlabel(\"Train Step\")\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","  \n","  return tf.reduce_mean(loss_)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[],"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n","    name='train_accuracy')\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["transformer = Transformer(num_layers, d_model, num_heads, dff,\n","                          input_vocab_size, target_vocab_size, \n","                          pe_input=input_vocab_size, \n","                          pe_target=target_vocab_size,\n","                          rate=dropout_rate)\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["def create_masks(inp, tar):\n","  # 编码器填充遮挡\n","  enc_padding_mask = create_padding_mask(inp)\n","  \n","  # 在解码器的第二个注意力模块使用。\n","  # 该填充遮挡用于遮挡编码器的输出。\n","  dec_padding_mask = create_padding_mask(inp)\n","  \n","  # 在解码器的第一个注意力模块使用。\n","  # 用于填充（pad）和遮挡（mask）解码器获取到的输入的后续标记（future tokens）。\n","  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n","  dec_target_padding_mask = create_padding_mask(tar)\n","  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n","  \n","  return enc_padding_mask, combined_mask, dec_padding_mask\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Latest checkpoint restored!!\n"]}],"source":["checkpoint_path = \"/home/xujingzhou/checkpoint3\"\n","\n","ckpt = tf.train.Checkpoint(transformer=transformer,\n","                           optimizer=optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# 如果检查点存在，则恢复最新的检查点。\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["EPOCHS = 1\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# 该 @tf.function 将追踪-编译 train_step 到 TF 图中，以便更快地\n","# 执行。该函数专用于参数张量的精确形状。为了避免由于可变序列长度或可变\n","# 批次大小（最后一批次较小）导致的再追踪，使用 input_signature 指定\n","# 更多的通用形状。\n","\n","train_step_signature = [\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n","]\n","\n","@tf.function(input_signature=train_step_signature)\n","def train_step(inp, tar):\n","  tar_inp = tar[:, :-1]\n","  tar_real = tar[:, 1:]\n","  \n","  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n","  \n","  with tf.GradientTape() as tape:\n","    predictions, _ = transformer(inp, tar_inp, \n","                                 True, \n","                                 enc_padding_mask, \n","                                 combined_mask, \n","                                 dec_padding_mask)\n","    loss = loss_function(tar_real, predictions)\n","\n","  gradients = tape.gradient(loss, transformer.trainable_variables)    \n","  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n","  \n","  train_loss(loss)\n","  train_accuracy(tar_real, predictions)\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["for epoch in range(EPOCHS):\n","  start = time.time()\n","  \n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  \n","  # inp -> portuguese, tar -> english\n","  for (batch, (inp, tar)) in enumerate(train_dataset):\n","    train_step(inp, tar)\n","    \n","    if batch % 50 == 0:\n","      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n","          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n","      \n","  if (epoch + 1) % 2 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","    \n","  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n","                                                train_loss.result(), \n","                                                train_accuracy.result()))\n","\n","  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#en和zh弄反了呜呜呜呜呜呜呜呜呜呜呜！！\n","def evaluate(inp_sentence):\n","  start_token = [tokenizer_en.vocab_size]\n","  end_token = [tokenizer_en.vocab_size + 1]\n","  \n","  # 输入语句是葡萄牙语，增加开始和结束标记\n","  inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n","  encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","  # 因为目标是英语，输入 transformer 的第一个词应该是\n","  # 英语的开始标记。\n","  decoder_input = [tokenizer_zh.vocab_size]\n","  output = tf.expand_dims(decoder_input, 0)\n","    \n","  for i in range(MAX_LENGTH):\n","    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","        encoder_input, output)\n","  \n","    # predictions.shape == (batch_size, seq_len, vocab_size)\n","    predictions, attention_weights = transformer(encoder_input, \n","                                                 output,\n","                                                 False,\n","                                                 enc_padding_mask,\n","                                                 combined_mask,\n","                                                 dec_padding_mask)\n","    \n","    # 从 seq_len 维度选择最后一个词\n","    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","    \n","    # 如果 predicted_id 等于结束标记，就返回结果\n","    if predicted_id == tokenizer_zh.vocab_size+1:\n","      return tf.squeeze(output, axis=0), attention_weights\n","    \n","    # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n","    output = tf.concat([output, predicted_id], axis=-1)\n","\n","  return tf.squeeze(output, axis=0), attention_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#这个是错误的错误！是妥协！\n","# def evaluate(inp_sentence):\n","#   start_token = [tokenizer_zh.vocab_size]\n","#   end_token = [tokenizer_zh.vocab_size + 1]\n","  \n","#   # 输入语句是葡萄牙语，增加开始和结束标记\n","#   inp_sentence = start_token + tokenizer_en.encode(inp_sentence) + end_token\n","#   encoder_input = tf.expand_dims(inp_sentence, 0)\n","  \n","#   # 因为目标是英语，输入 transformer 的第一个词应该是\n","#   # 英语的开始标记。\n","#   decoder_input = [tokenizer_en.vocab_size]\n","#   output = tf.expand_dims(decoder_input, 0)\n","    \n","#   for i in range(MAX_LENGTH):\n","#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n","#         encoder_input, output)\n","  \n","#     # predictions.shape == (batch_size, seq_len, vocab_size)\n","#     predictions, attention_weights = transformer(encoder_input, \n","#                                                  output,\n","#                                                  False,\n","#                                                  enc_padding_mask,\n","#                                                  combined_mask,\n","#                                                  dec_padding_mask)\n","    \n","#     # 从 seq_len 维度选择最后一个词\n","#     predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n","\n","#     predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","    \n","#     # 如果 predicted_id 等于结束标记，就返回结果\n","#     if predicted_id == tokenizer_en.vocab_size+1:\n","#       return tf.squeeze(output, axis=0), attention_weights\n","    \n","#     # 连接 predicted_id 与输出，作为解码器的输入传递到解码器。\n","#     output = tf.concat([output, predicted_id], axis=-1)\n","\n","#   return tf.squeeze(output, axis=0), attention_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_attention_weights(attention, sentence, result, layer):\n","  fig = plt.figure(figsize=(16, 8))\n","  \n","  sentence = tokenizer_en.encode(sentence)\n","  \n","  attention = tf.squeeze(attention[layer], axis=0)\n","  \n","  for head in range(attention.shape[0]):\n","    ax = fig.add_subplot(2, 4, head+1)\n","    \n","    # 画出注意力权重\n","    ax.matshow(attention[head][:-1, :], cmap='viridis')\n","\n","    fontdict = {'fontsize': 10}\n","    \n","    ax.set_xticks(range(len(sentence)+2))\n","    ax.set_yticks(range(len(result)))\n","    \n","    ax.set_ylim(len(result)-1.5, -0.5)\n","        \n","    ax.set_xticklabels(\n","        ['<start>']+[tokenizer_en.decode([i]) for i in sentence]+['<end>'], \n","        fontdict=fontdict, rotation=90)\n","    \n","    ax.set_yticklabels([tokenizer_zh.decode([i]) for i in result \n","                        if i < tokenizer_zh.vocab_size], \n","                       fontdict=fontdict)\n","    \n","    ax.set_xlabel('Head {}'.format(head+1))\n","  \n","  plt.tight_layout()\n","  plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def translate(sentence, plot=''):\n","  result, attention_weights = evaluate(sentence)\n","  print(result)\n","  predicted_sentence = tokenizer_zh.decode([i for i in result \n","                                            if i < tokenizer_zh.vocab_size])  \n","\n","  print('Input: {}'.format(sentence))\n","  print('Predicted translation: {}'.format(predicted_sentence))\n","  \n","  if plot:\n","    plot_attention_weights(attention_weights, sentence, result, plot)\n","\n"]}],"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.6.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
